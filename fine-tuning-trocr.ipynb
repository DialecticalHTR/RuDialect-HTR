{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3977616,"sourceType":"datasetVersion","datasetId":1502872},{"sourceId":11172706,"sourceType":"datasetVersion","datasetId":6783285},{"sourceId":11172869,"sourceType":"datasetVersion","datasetId":6972229},{"sourceId":281611,"sourceType":"modelInstanceVersion","modelInstanceId":234131,"modelId":255833},{"sourceId":304218,"sourceType":"modelInstanceVersion","modelInstanceId":259644,"modelId":280823},{"sourceId":311060,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":263810,"modelId":284907}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0 Download Kaggle Data to Google Drive","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y -q cffi\n!pip install -q cffi gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:26.605402Z","iopub.execute_input":"2025-03-31T10:11:26.605743Z","iopub.status.idle":"2025-03-31T10:11:32.462146Z","shell.execute_reply.started":"2025-03-31T10:11:26.605718Z","shell.execute_reply":"2025-03-31T10:11:32.460994Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"url = \"\" # paste your URL link to the Google Cloud service account key\n!gdown --fuzzy {url}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:32.463893Z","iopub.execute_input":"2025-03-31T10:11:32.464244Z","iopub.status.idle":"2025-03-31T10:11:32.956274Z","shell.execute_reply.started":"2025-03-31T10:11:32.464202Z","shell.execute_reply":"2025-03-31T10:11:32.955438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from googleapiclient.discovery import build\nfrom google.oauth2.service_account import Credentials\n\n\nSERVICE_ACCOUNT_FILE = \"/kaggle/working/your-service-account-3.json\" # paste the service account key you downloaded\n\n# Create credentials\ncreds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE)\n\n# Create service Google Drive API\ndrive_service = build(\"drive\", \"v3\", credentials=creds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:32.958045Z","iopub.execute_input":"2025-03-31T10:11:32.958342Z","iopub.status.idle":"2025-03-31T10:11:33.009155Z","shell.execute_reply.started":"2025-03-31T10:11:32.958306Z","shell.execute_reply":"2025-03-31T10:11:33.008428Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1 Preprocessing datasets","metadata":{}},{"cell_type":"code","source":"!pip install -q transformers evaluate jiwer peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:33.010460Z","iopub.execute_input":"2025-03-31T10:11:33.010669Z","iopub.status.idle":"2025-03-31T10:11:36.324412Z","shell.execute_reply.started":"2025-03-31T10:11:33.010651Z","shell.execute_reply":"2025-03-31T10:11:36.323184Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.1 Data loading and preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom peft import LoraConfig, get_peft_model\nfrom transformers import VisionEncoderDecoderModel, TrOCRProcessor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:36.325745Z","iopub.execute_input":"2025-03-31T10:11:36.326129Z","iopub.status.idle":"2025-03-31T10:11:36.332270Z","shell.execute_reply.started":"2025-03-31T10:11:36.326094Z","shell.execute_reply":"2025-03-31T10:11:36.331254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 5\nbatch_size = 16\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    multi_gpu = True\nelse:\n    multi_gpu = False\n\nprint(f\"num_epochs: {num_epochs} and batch_size: {batch_size}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:36.333354Z","iopub.execute_input":"2025-03-31T10:11:36.333637Z","iopub.status.idle":"2025-03-31T10:11:36.354157Z","shell.execute_reply.started":"2025-03-31T10:11:36.333615Z","shell.execute_reply":"2025-03-31T10:11:36.353239Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# split data into 'num_files' parts if necessary\ndef split_data(df: pd.DataFrame, num_files: int, name_df: str):\n    path = os.path.join(\"/kaggle/working\", name_df)\n    \n    try:\n        os.makedirs(path, exist_ok=True)\n        df_list = np.array_split(df, num_files)\n        \n        for i, df_part in enumerate(df_list):\n            df_part.to_csv(f\"{path}/{name_df}_chunk{i}.csv\", sep=';', header=None, index=False, escapechar='\\\\')\n        print(f\"{name_df} data is splitted\")\n            \n    except OSError as error:\n        print(\"Directory can not be created\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:36.355156Z","iopub.execute_input":"2025-03-31T10:11:36.355467Z","iopub.status.idle":"2025-03-31T10:11:36.367515Z","shell.execute_reply.started":"2025-03-31T10:11:36.355437Z","shell.execute_reply":"2025-03-31T10:11:36.366577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"real_train_df = pd.read_csv(\n    \"/kaggle/input/dialectic-real-all/data.csv\",\n    sep=\";\",\n    escapechar='\\\\',\n    skiprows=1,\n    header=None,\n    names=[\"file_name\", \"text\"],\n)\n\nreal_train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:36.370731Z","iopub.execute_input":"2025-03-31T10:11:36.370958Z","iopub.status.idle":"2025-03-31T10:11:36.410628Z","shell.execute_reply.started":"2025-03-31T10:11:36.370939Z","shell.execute_reply":"2025-03-31T10:11:36.409882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stackmix_train_df = pd.read_csv(\n    \"/kaggle/input/dialectic-stackmix-1/data.csv\",\n    sep=\";\",    \n    escapechar='\\\\',\n    header=None,\n    skiprows=1,\n    names=[\"text\", \"file_name\"],\n)\n\nstackmix_train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:36.412362Z","iopub.execute_input":"2025-03-31T10:11:36.412643Z","iopub.status.idle":"2025-03-31T10:11:36.817121Z","shell.execute_reply.started":"2025-03-31T10:11:36.412617Z","shell.execute_reply":"2025-03-31T10:11:36.816196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"split_data(df=stackmix_train_df, num_files=4, name_df=\"stackmix\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:36.818164Z","iopub.execute_input":"2025-03-31T10:11:36.818488Z","iopub.status.idle":"2025-03-31T10:11:37.166615Z","shell.execute_reply.started":"2025-03-31T10:11:36.818457Z","shell.execute_reply":"2025-03-31T10:11:37.165905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stackmix_train_df = pd.read_csv(\n    \"/kaggle/working/stackmix/stackmix_chunk0.csv\",\n    sep=\";\",    \n    escapechar='\\\\',\n    header=None,\n    skiprows=1,\n    names=[\"text\", \"file_name\"],\n)\n\nprint(f\"stackmix_train_df.shape: {stackmix_train_df.shape}\")\nstackmix_train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.167354Z","iopub.execute_input":"2025-03-31T10:11:37.167617Z","iopub.status.idle":"2025-03-31T10:11:37.266105Z","shell.execute_reply.started":"2025-03-31T10:11:37.167594Z","shell.execute_reply":"2025-03-31T10:11:37.265136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cyrillic_train_df = pd.read_csv(\n    \"/kaggle/input/cyrillic-handwriting-dataset/train.tsv\",\n    sep=\"\\t\",    \n    escapechar='\\\\',\n    header=None,\n    names=[\"file_name\", \"text\"],\n)\n\ncyrillic_train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.267228Z","iopub.execute_input":"2025-03-31T10:11:37.267579Z","iopub.status.idle":"2025-03-31T10:11:37.345746Z","shell.execute_reply.started":"2025-03-31T10:11:37.267544Z","shell.execute_reply":"2025-03-31T10:11:37.345040Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"split_data(df=cyrillic_train_df, num_files=4, name_df=\"cyrillic\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.346581Z","iopub.execute_input":"2025-03-31T10:11:37.346917Z","iopub.status.idle":"2025-03-31T10:11:37.425866Z","shell.execute_reply.started":"2025-03-31T10:11:37.346886Z","shell.execute_reply":"2025-03-31T10:11:37.425034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cyrillic_train_df = pd.read_csv(\n    \"/kaggle/working/cyrillic/cyrillic_chunk0.csv\",\n    sep=\";\",    \n    escapechar='\\\\',\n    header=None,    \n    names=[\"file_name\", \"text\"],\n)\n\nprint(f\"cyrillic_train_df.shape: {cyrillic_train_df.shape}\")\ncyrillic_train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.426487Z","iopub.execute_input":"2025-03-31T10:11:37.426686Z","iopub.status.idle":"2025-03-31T10:11:37.453269Z","shell.execute_reply.started":"2025-03-31T10:11:37.426668Z","shell.execute_reply":"2025-03-31T10:11:37.452644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(real_train_df.isnull().sum(), \"\\n\")\nprint(stackmix_train_df.isnull().sum(), \"\\n\")\nprint(cyrillic_train_df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.454043Z","iopub.execute_input":"2025-03-31T10:11:37.454337Z","iopub.status.idle":"2025-03-31T10:11:37.466860Z","shell.execute_reply.started":"2025-03-31T10:11:37.454307Z","shell.execute_reply":"2025-03-31T10:11:37.466223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"real_train_df = real_train_df.dropna()\nstackmix_train_df = stackmix_train_df.dropna()\ncyrillic_train_df = cyrillic_train_df.dropna()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.467744Z","iopub.execute_input":"2025-03-31T10:11:37.468009Z","iopub.status.idle":"2025-03-31T10:11:37.487607Z","shell.execute_reply.started":"2025-03-31T10:11:37.467980Z","shell.execute_reply":"2025-03-31T10:11:37.486958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# we reset the indices to start from zero\nreal_train_df.reset_index(drop=True, inplace=True)\nstackmix_train_df.reset_index(drop=True, inplace=True)\ncyrillic_train_df.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.488501Z","iopub.execute_input":"2025-03-31T10:11:37.488861Z","iopub.status.idle":"2025-03-31T10:11:37.494365Z","shell.execute_reply.started":"2025-03-31T10:11:37.488788Z","shell.execute_reply":"2025-03-31T10:11:37.493542Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MixedDataset(Dataset):        \n    def __init__(self, orig_root, orig_df, synth_root, synth_df, processor, orig_fraction=0.3, max_target_length=128):\n        self.orig_root = orig_root\n        self.orig_df = orig_df\n        self.synth_root = synth_root\n        self.synth_df = synth_df\n        \n        self.processor = processor\n        self.orig_fraction = orig_fraction\n        self.max_target_length = max_target_length\n\n        self.orig_size = len(orig_df)\n        self.synth_size = len(synth_df)\n\n        self.orig_indices = list(range(self.orig_size))\n        self.synth_indices = list(range(self.synth_size))        \n\n    def __len__(self):\n        return self.orig_size + self.synth_size\n\n    def __getitem__(self, index, return_image=False):\n        use_original = (index % (1 / self.orig_fraction)) < 1\n        if use_original:\n            sample_idx = self.orig_indices[index % self.orig_size]\n            file_name = self.orig_df[\"file_name\"][sample_idx]\n            text = self.orig_df[\"text\"][sample_idx]\n            image_path = self.orig_root + file_name\n            image = Image.open(image_path).convert(\"RGB\")\n\n        else:\n            sample_idx = self.synth_indices[index % self.synth_size]\n            file_name = self.synth_df[\"file_name\"][sample_idx]\n            text = self.synth_df[\"text\"][sample_idx]\n            image_path = self.synth_root + file_name\n            image = Image.open(image_path).convert(\"RGB\")\n\n        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n        labels = self.processor.tokenizer(text, padding=\"max_length\", max_length=self.max_target_length).input_ids\n                \n        # important: make sure that PAD tokens are ignored by the loss function\n        labels = [\n            label if label != self.processor.tokenizer.pad_token_id else -100\n            for label in labels\n        ]\n\n        encoding = {\n            \"pixel_values\": pixel_values.squeeze(),\n            \"labels\": torch.tensor(labels),\n        }\n\n        if return_image:            \n            return encoding, image\n            \n        return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.495284Z","iopub.execute_input":"2025-03-31T10:11:37.495592Z","iopub.status.idle":"2025-03-31T10:11:37.505861Z","shell.execute_reply.started":"2025-03-31T10:11:37.495562Z","shell.execute_reply":"2025-03-31T10:11:37.505231Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CHDataset(Dataset):\n    def __init__(self, df, processor, root_dir=None, max_target_length=128):\n        self.root_dir = root_dir\n        self.df = df\n        self.processor = processor\n        self.max_target_length = max_target_length        \n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx, return_image=False):\n        # get file name + text\n        file_name = self.df[\"file_name\"][idx]\n        text = self.df[\"text\"][idx]\n        \n        # prepare image (i.e. resize + normalize)\n        image = Image.open(self.root_dir + file_name).convert(\"RGB\")            \n        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n        \n        # add labels (input_ids) by encoding the text\n        labels = self.processor.tokenizer(text, padding=\"max_length\", max_length=self.max_target_length).input_ids\n        \n        # important: make sure that PAD tokens are ignored by the loss function    \n        labels = [\n            label if label != self.processor.tokenizer.pad_token_id else -100\n            for label in labels\n        ]\n\n        encoding = {\n            \"pixel_values\": pixel_values.squeeze(),\n            \"labels\": torch.tensor(labels),\n        }\n        if return_image:\n            return encoding, image\n        \n        return encoding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.506562Z","iopub.execute_input":"2025-03-31T10:11:37.506829Z","iopub.status.idle":"2025-03-31T10:11:37.522654Z","shell.execute_reply.started":"2025-03-31T10:11:37.506789Z","shell.execute_reply":"2025-03-31T10:11:37.521872Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.2 Creating dataloaders","metadata":{}},{"cell_type":"code","source":"model_name = \"/kaggle/input/dialectic-stackmix-2.0-dora-1.4/other/default/1\" # paste your TrOCR model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.523493Z","iopub.execute_input":"2025-03-31T10:11:37.523710Z","iopub.status.idle":"2025-03-31T10:11:37.537790Z","shell.execute_reply.started":"2025-03-31T10:11:37.523692Z","shell.execute_reply":"2025-03-31T10:11:37.537108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"processor = TrOCRProcessor.from_pretrained(model_name)\n\nvocab = processor.tokenizer.get_vocab()\ndiacritic_chars = list(\"\\u0301\\u0302\\u0304\\u0311\\u0306\\u203f\")\nmissing_tokens = [char for char in diacritic_chars if char not in vocab]\n\nif missing_tokens:\n    print(\"Missing characters:\", missing_tokens)\n    processor.tokenizer.add_tokens(missing_tokens)\n    model.decoder.resize_token_embeddings(len(processor.tokenizer))\n\nelse:\n    print(\"All the necessary characters are already present in vocab.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.538613Z","iopub.execute_input":"2025-03-31T10:11:37.538879Z","iopub.status.idle":"2025-03-31T10:11:37.735207Z","shell.execute_reply.started":"2025-03-31T10:11:37.538847Z","shell.execute_reply":"2025-03-31T10:11:37.734203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = MixedDataset(    \n    orig_root=\"/kaggle/input/cyrillic-handwriting-dataset/train/\",\n    orig_df=cyrillic_train_df,\n    synth_root=\"/kaggle/input/dialectic-stackmix-1/images/\",\n    synth_df=stackmix_train_df,\n    processor=processor,\n    orig_fraction=0.5,\n)\n\nval_dataset = CHDataset(\n    root_dir=\"/kaggle/input/dialectic-real-all/images/\",\n    df=real_train_df,\n    processor=processor\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.736076Z","iopub.execute_input":"2025-03-31T10:11:37.736335Z","iopub.status.idle":"2025-03-31T10:11:37.741959Z","shell.execute_reply.started":"2025-03-31T10:11:37.736314Z","shell.execute_reply":"2025-03-31T10:11:37.740991Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Number of training examples:\", len(train_dataset))\nprint(\"Number of cards val examples:\", len(val_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.745762Z","iopub.execute_input":"2025-03-31T10:11:37.746014Z","iopub.status.idle":"2025-03-31T10:11:37.760053Z","shell.execute_reply.started":"2025-03-31T10:11:37.745994Z","shell.execute_reply":"2025-03-31T10:11:37.759353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n    labels = [item[\"labels\"] for item in batch]\n    labels_padded = pad_sequence(labels, batch_first=True, padding_value=-100)\n    return {\"pixel_values\": pixel_values, \"labels\": labels_padded}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.761396Z","iopub.execute_input":"2025-03-31T10:11:37.761630Z","iopub.status.idle":"2025-03-31T10:11:37.773849Z","shell.execute_reply.started":"2025-03-31T10:11:37.761610Z","shell.execute_reply":"2025-03-31T10:11:37.773078Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True, num_workers=4, pin_memory=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=custom_collate_fn, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.774575Z","iopub.execute_input":"2025-03-31T10:11:37.774855Z","iopub.status.idle":"2025-03-31T10:11:37.804325Z","shell.execute_reply.started":"2025-03-31T10:11:37.774823Z","shell.execute_reply":"2025-03-31T10:11:37.803523Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.3 Checking Decoder","metadata":{}},{"cell_type":"code","source":"# if you also want to get the image, set 'return_image' in __get_item__ to 'True'\n# encoding, image = train_dataset[0]\nencoding = train_dataset[0]\nfor k, v in encoding.items():\n   print(k, v.shape)\n\n\nlabels = encoding['labels']\nlabels[labels == -100] = processor.tokenizer.pad_token_id\nlabel_str = processor.decode(labels, skip_special_tokens=True)\nprint(label_str)\n\n# image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.804976Z","iopub.execute_input":"2025-03-31T10:11:37.805181Z","iopub.status.idle":"2025-03-31T10:11:37.833003Z","shell.execute_reply.started":"2025-03-31T10:11:37.805163Z","shell.execute_reply":"2025-03-31T10:11:37.832207Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2 Fine-tuning","metadata":{}},{"cell_type":"code","source":"import evaluate\nfrom transformers import GenerationConfig, TrainingArguments\n\nimport copy\n\nfrom tqdm.auto import tqdm\nfrom torch.optim import AdamW\nfrom torch.utils.tensorboard import SummaryWriter\nfrom transformers import get_linear_schedule_with_warmup\n\nfrom accelerate import Accelerator\nfrom accelerate.utils import LoggerType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.833630Z","iopub.execute_input":"2025-03-31T10:11:37.833848Z","iopub.status.idle":"2025-03-31T10:11:37.837933Z","shell.execute_reply.started":"2025-03-31T10:11:37.833828Z","shell.execute_reply":"2025-03-31T10:11:37.837113Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = VisionEncoderDecoderModel.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:37.838592Z","iopub.execute_input":"2025-03-31T10:11:37.838843Z","iopub.status.idle":"2025-03-31T10:11:43.829112Z","shell.execute_reply.started":"2025-03-31T10:11:37.838795Z","shell.execute_reply":"2025-03-31T10:11:43.828150Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.1 DoRA","metadata":{}},{"cell_type":"code","source":"dora_config = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"query\", \"value\", \"q_proj\", \"v_proj\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    use_dora=True,\n    use_rslora=True,    \n)\nmodel = get_peft_model(model, dora_config)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:43.830345Z","iopub.execute_input":"2025-03-31T10:11:43.830667Z","iopub.status.idle":"2025-03-31T10:11:44.099585Z","shell.execute_reply.started":"2025-03-31T10:11:43.830638Z","shell.execute_reply":"2025-03-31T10:11:44.098635Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:44.100452Z","iopub.execute_input":"2025-03-31T10:11:44.100832Z","iopub.status.idle":"2025-03-31T10:11:44.112136Z","shell.execute_reply.started":"2025-03-31T10:11:44.100783Z","shell.execute_reply":"2025-03-31T10:11:44.111257Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.2 Metrics and tools","metadata":{}},{"cell_type":"code","source":"cer_metric = evaluate.load(\"cer\")\nwer_metric = evaluate.load(\"wer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:44.113014Z","iopub.execute_input":"2025-03-31T10:11:44.113295Z","iopub.status.idle":"2025-03-31T10:11:44.691992Z","shell.execute_reply.started":"2025-03-31T10:11:44.113269Z","shell.execute_reply":"2025-03-31T10:11:44.690848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# only CER and WER\ndef compute_metrics(pred_ids, label_ids):\n   pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n   label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n   label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n\n   cer = cer_metric.compute(predictions=pred_str, references=label_str)\n   wer = wer_metric.compute(predictions=pred_str, references=label_str)   \n\n   return cer, wer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:44.693100Z","iopub.execute_input":"2025-03-31T10:11:44.693415Z","iopub.status.idle":"2025-03-31T10:11:44.699144Z","shell.execute_reply.started":"2025-03-31T10:11:44.693384Z","shell.execute_reply":"2025-03-31T10:11:44.698204Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def string_accuracy(pred_ids, label_ids) -> float:\n    correct = 0\n    \n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n    \n    pred_texts = pred_str\n    gt_texts = label_str\n    \n    assert len(pred_texts) == len(gt_texts)\n    \n    for pred_text, gt_text in zip(pred_texts, gt_texts):\n        correct += int(pred_text == gt_text)\n        \n    return correct / len(gt_texts) * 100.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:44.700164Z","iopub.execute_input":"2025-03-31T10:11:44.700450Z","iopub.status.idle":"2025-03-31T10:11:44.724374Z","shell.execute_reply.started":"2025-03-31T10:11:44.700423Z","shell.execute_reply":"2025-03-31T10:11:44.723504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(model, dataloader, device):\n    model.eval()\n    total_cer, total_wer, total_accuracy = 0.0, 0.0, 0.0\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            outputs = model.generate(batch[\"pixel_values\"].to(device))\n            \n            cer, wer = compute_metrics(pred_ids=outputs, label_ids=batch[\"labels\"])\n            accuracy = string_accuracy(pred_ids=outputs, label_ids=batch[\"labels\"])\n\n            total_cer += cer\n            total_wer += wer\n            total_accuracy += accuracy          \n    \n    dataset_size = len(dataloader)\n    return {\n        \"CER\": total_cer / dataset_size,\n        \"WER\": total_wer / dataset_size,\n        \"Accuracy\": total_accuracy / dataset_size\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:44.725050Z","iopub.execute_input":"2025-03-31T10:11:44.725330Z","iopub.status.idle":"2025-03-31T10:11:44.735098Z","shell.execute_reply.started":"2025-03-31T10:11:44.725300Z","shell.execute_reply":"2025-03-31T10:11:44.734188Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def beam_search(model):\n    # set special tokens used for creating the decoder_input_ids from the labels\n    model.config.decoder_start_token_id = processor.tokenizer.cls_token_id    \n    model.config.pad_token_id = processor.tokenizer.pad_token_id\n    model.config.vocab_size = model.config.decoder.vocab_size\n    \n    \n    # set beam search parameters\n    generation_config = GenerationConfig(\n        eos_token_id=processor.tokenizer.sep_token_id,\n        max_length=64,\n        early_stopping=True,\n        no_repeat_ngram_size=3,\n        length_penalty=2.0,\n        num_beams=4\n    )\n    model.generation_config = generation_config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:44.736602Z","iopub.execute_input":"2025-03-31T10:11:44.736893Z","iopub.status.idle":"2025-03-31T10:11:44.753698Z","shell.execute_reply.started":"2025-03-31T10:11:44.736867Z","shell.execute_reply":"2025-03-31T10:11:44.752762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Configuring generation parameters\nbeam_search(model)\n\nif multi_gpu:\n    model = torch.nn.DataParallel(model)\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:44.754621Z","iopub.execute_input":"2025-03-31T10:11:44.754940Z","iopub.status.idle":"2025-03-31T10:11:45.145256Z","shell.execute_reply.started":"2025-03-31T10:11:44.754905Z","shell.execute_reply":"2025-03-31T10:11:45.144375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.3 Auxiliary functions","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\nimport shutil\nimport time\nimport socket\nimport ssl\n\nfrom google.oauth2.service_account import Credentials\nfrom googleapiclient.discovery import build\nfrom googleapiclient.http import MediaFileUpload\nfrom googleapiclient.errors import HttpError\n\n\nFOLDER_ID = \"\" # paste folder ID from your Google Drive\n\ndef create_zip(folder_to_zip, zip_path):    \n    base_name = zip_path[:-4]\n    shutil.make_archive(base_name=base_name, format='zip', root_dir=folder_to_zip)\n    folder_name = os.path.basename(folder_to_zip)\n    print(f\"Zip archive of the {folder_name} created\")\n\n\ndef upload_to_drive(file_path, file_name, folder_id, max_retries=5):    \n    file_metadata = {\n        \"name\": file_name,\n        \"parents\": [folder_id]\n    }\n\n    media = MediaFileUpload(file_path, mimetype=\"application/zip\")\n    \n    for attempt in range(max_retries):\n        try:\n            file = drive_service.files().create(body=file_metadata, media_body=media).execute()\n            print(f\"File {file_name} uploaded to Google Drive\")\n            return\n        except (HttpError, ssl.SSLEOFError, socket.timeout) as e:\n            print(f\"Uploading error: {e}, attempt {attempt+1} from {max_retries}\")\n            time.sleep(5)\n            \n    print(f\"Failed to upload {file_name} after {max_retries} attempts. We continue to execute...\")\n\n\ndef main_model():\n    zip_path = \"/kaggle/working/dialectic-stackmix-2.0-dora-1.4.zip\"\n    folder_to_zip = \"/kaggle/working/model\"\n\n    if os.path.exists(zip_path):\n        os.remove(zip_path)\n    \n    create_zip(folder_to_zip, zip_path)    \n    upload_to_drive(zip_path, \"dialectic-stackmix-2.0-dora-1.4.zip\", FOLDER_ID)\n\ndef main_logs():\n    zip_path = \"/kaggle/working/dialectic-stackmix-2.0-dora-1.4-logs.zip\"\n    folder_to_zip = \"/kaggle/working/logs\"\n\n    if os.path.exists(zip_path):\n        os.remove(zip_path)\n    \n    create_zip(folder_to_zip, zip_path)        \n    upload_to_drive(zip_path, \"dialectic-stackmix-2.0-dora-1.4-logs.zip\", FOLDER_ID)\n\ndef zip_best_model():\n    zip_path = \"/kaggle/working/best_model-dialectic-stackmix-2.0-dora-1.4.zip\"\n    folder_to_zip = \"/kaggle/working/model/TrOCRModel/best_model\"\n\n    if os.path.exists(zip_path):\n        os.remove(zip_path)\n\n    create_zip(folder_to_zip, zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:45.146190Z","iopub.execute_input":"2025-03-31T10:11:45.146507Z","iopub.status.idle":"2025-03-31T10:11:45.154891Z","shell.execute_reply.started":"2025-03-31T10:11:45.146479Z","shell.execute_reply":"2025-03-31T10:11:45.154046Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2.4 Using Accelerate","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:45.155962Z","iopub.execute_input":"2025-03-31T10:11:45.156267Z","iopub.status.idle":"2025-03-31T10:11:45.171747Z","shell.execute_reply.started":"2025-03-31T10:11:45.156238Z","shell.execute_reply":"2025-03-31T10:11:45.170876Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"model/TrOCRModel/weights\",\n    learning_rate=5e-5,\n    num_train_epochs=num_epochs,\n    logging_dir=\"logs\",\n    fp16=True,    \n    gradient_accumulation_steps=2,\n)\n\nbest_cer = float(\"inf\")\nbest_model_path = os.path.join(\"model/TrOCRModel\", \"best_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:45.172491Z","iopub.execute_input":"2025-03-31T10:11:45.172723Z","iopub.status.idle":"2025-03-31T10:11:46.005732Z","shell.execute_reply.started":"2025-03-31T10:11:45.172703Z","shell.execute_reply":"2025-03-31T10:11:46.004844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accelerator = Accelerator(\n    mixed_precision=\"fp16\" if training_args.fp16 else \"no\",\n    gradient_accumulation_steps=training_args.gradient_accumulation_steps,\n)\n\nif accelerator.is_main_process:\n    writer = SummaryWriter(log_dir=training_args.logging_dir)\n\noptimizer = AdamW(model.parameters(), lr=training_args.learning_rate)\nnum_training_steps = len(train_dataloader) * training_args.num_train_epochs\nwarmup_steps=int(0.1 * num_training_steps)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=warmup_steps,\n    num_training_steps=num_training_steps\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:46.006659Z","iopub.execute_input":"2025-03-31T10:11:46.006979Z","iopub.status.idle":"2025-03-31T10:11:46.024154Z","shell.execute_reply.started":"2025-03-31T10:11:46.006948Z","shell.execute_reply":"2025-03-31T10:11:46.023398Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, optimizer, train_dataloader, val_dataloader, scheduler = accelerator.prepare(\n    model, \n    optimizer,\n    train_dataloader, \n    val_dataloader,\n    scheduler,\n)\n\nfor epoch in range(training_args.num_train_epochs):\n    model.train()\n    train_loss = 0.0\n\n    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\", disable=not accelerator.is_local_main_process)\n\n    for batch in progress_bar:\n        with accelerator.accumulate(model):\n            optimizer.zero_grad()\n        \n            outputs = model(**batch)\n            loss = outputs.loss.mean()\n\n            accelerator.backward(loss)\n            optimizer.step()\n            scheduler.step()\n\n            train_loss += loss.item()\n            progress_bar.set_postfix(loss=loss.item())\n\n    avg_train_loss = train_loss / len(train_dataloader)    \n\n    # Validation\n    model_copy = copy.deepcopy(model.module)\n    merged_model = model_copy.merge_and_unload()\n    metrics = evaluate_model(merged_model, val_dataloader, accelerator.device)    \n    print(f\"Validation CER: {metrics['CER']:.4f}, WER: {metrics['WER']:.4f}, Accuracy: {metrics['Accuracy']:.2f}%, Train loss: {avg_train_loss:.2f}\")\n\n    # Logging on main process\n    if accelerator.is_main_process:\n        writer.add_scalar(\"Loss/train\", avg_train_loss, epoch)\n        writer.add_scalar(\"Metrics/CER\", metrics[\"CER\"], epoch)\n        writer.add_scalar(\"Metrics/WER\", metrics[\"WER\"], epoch)\n        writer.add_scalar(\"Metrics/Accuracy\", metrics[\"Accuracy\"], epoch)\n\n    # Save the best model\n    if metrics[\"CER\"] < best_cer:\n        best_cer = metrics[\"CER\"]\n        \n        if accelerator.is_main_process:\n            print(f\"New best CER: {best_cer:.4f}. Saving copy merged model...\")\n            unwrapped_model = accelerator.unwrap_model(merged_model)\n            unwrapped_model.save_pretrained(best_model_path)\n            processor.save_pretrained(best_model_path)\n            zip_best_model()\n    \n    accelerator.wait_for_everyone()\n    torch.cuda.empty_cache()\n\n\nmerged_model = model.module.merge_and_unload()\nprocessor.save_pretrained(training_args.output_dir)\nunwrapped_model = accelerator.unwrap_model(merged_model)\nunwrapped_model.save_pretrained(training_args.output_dir)\n\naccelerator.end_training()\naccelerator.save_state(os.path.join(\"model/TrOCRModel/saves_states\", \"checkpoint\"))\n\nif accelerator.is_main_process:\n    writer.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:11:46.024996Z","iopub.execute_input":"2025-03-31T10:11:46.025285Z","iopub.status.idle":"2025-03-31T10:20:54.018191Z","shell.execute_reply.started":"2025-03-31T10:11:46.025254Z","shell.execute_reply":"2025-03-31T10:20:54.016758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Upload your last model and logs to Google Drive\nmain_model()\nmain_logs()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:21:04.219357Z","iopub.execute_input":"2025-03-31T10:21:04.219658Z","iopub.status.idle":"2025-03-31T10:25:04.113904Z","shell.execute_reply.started":"2025-03-31T10:21:04.219631Z","shell.execute_reply":"2025-03-31T10:25:04.113115Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3 Test","metadata":{}},{"cell_type":"code","source":"from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n\n\nmodel_name = \"/kaggle/input/dialectic-stackmix-2.0-dora-1.4/other/default/1\"\nprocessor = TrOCRProcessor.from_pretrained(\n   model_name\n)\nmodel = VisionEncoderDecoderModel.from_pretrained(\n   model_name\n)\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:25:58.356503Z","iopub.execute_input":"2025-03-31T10:25:58.356920Z","iopub.status.idle":"2025-03-31T10:26:04.668311Z","shell.execute_reply.started":"2025-03-31T10:25:58.356884Z","shell.execute_reply":"2025-03-31T10:26:04.667514Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = evaluate_model(model, val_dataloader, device)\nfor k, v in results.items():\n    print(f\"{k}: {v}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:20:54.023064Z","iopub.status.idle":"2025-03-31T10:20:54.023523Z","shell.execute_reply":"2025-03-31T10:20:54.023324Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\n\npath = \"/kaggle/input/dialectic-real-all/images\"\ncnt = 0\nfor root, _, files in os.walk(path):    \n    for file in files:\n        file_path = os.path.join(root, file)\n        image = Image.open(file_path).convert(\"RGB\")        \n        pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n        \n        generated_ids = model.generate(pixel_values)\n        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n        print(generated_text)\n        \n        plt.imshow(image)\n        plt.show()\n        \n        cnt += 1        \n        if cnt == 5:\n            break    \n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-31T10:28:34.965145Z","iopub.execute_input":"2025-03-31T10:28:34.965654Z","iopub.status.idle":"2025-03-31T10:28:43.176133Z","shell.execute_reply.started":"2025-03-31T10:28:34.965604Z","shell.execute_reply":"2025-03-31T10:28:43.175262Z"}},"outputs":[],"execution_count":null}]}