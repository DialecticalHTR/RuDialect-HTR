{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["2tecCgQeZSxU","QmmvZASGZUBs","U3cvcaqoarcS"]},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":432423,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":352521,"modelId":373800},{"sourceId":432427,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":352525,"modelId":373804}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\n\n\ntmp = Path(\"/kaggle/tmp\")\ntmp.mkdir(exist_ok=True, parents=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:38.731527Z","iopub.execute_input":"2025-06-13T09:50:38.733375Z","iopub.status.idle":"2025-06-13T09:50:38.739871Z","shell.execute_reply.started":"2025-06-13T09:50:38.733282Z","shell.execute_reply":"2025-06-13T09:50:38.738768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q ultralytics transformers","metadata":{"id":"iCOIJwU8Mbhi","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:38.741537Z","iopub.execute_input":"2025-06-13T09:50:38.741846Z","iopub.status.idle":"2025-06-13T09:50:43.628399Z","shell.execute_reply.started":"2025-06-13T09:50:38.741824Z","shell.execute_reply":"2025-06-13T09:50:43.626995Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Download test image","metadata":{"id":"qg2MGj24YpOE"}},{"cell_type":"code","source":"!gdown --fuzzy https://drive.google.com/file/d/1l9p59MrCcTrmeiSWzptVrAb-vE4hlLo5/view?usp=sharing\n!mv /kaggle/working/\"Copy of 2.jpg\" /kaggle/tmp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:43.631031Z","iopub.execute_input":"2025-06-13T09:50:43.631462Z","iopub.status.idle":"2025-06-13T09:50:48.409655Z","shell.execute_reply.started":"2025-06-13T09:50:43.631419Z","shell.execute_reply":"2025-06-13T09:50:48.408215Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\n\n\nimgs = []\npaths = [\"/kaggle/tmp/Copy of 2.jpg\"]\n\nfor path in paths:\n    image = cv2.imread(path)\n    image = cv2.resize(image, (1280, 900))\n    imgs.append(image)","metadata":{"id":"8nch5OhXNpma","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:48.411243Z","iopub.execute_input":"2025-06-13T09:50:48.411634Z","iopub.status.idle":"2025-06-13T09:50:48.498459Z","shell.execute_reply.started":"2025-06-13T09:50:48.411547Z","shell.execute_reply":"2025-06-13T09:50:48.497293Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model loading and configuration","metadata":{}},{"cell_type":"markdown","source":"## YOLO","metadata":{"id":"2tecCgQeZSxU"}},{"cell_type":"code","source":"from ultralytics import YOLO\n\n\ntext_detection = YOLO(\"/kaggle/input/yolo11x-dialectic/pytorch/default/1/best.pt\")","metadata":{"id":"J2fpQcCmMnhT","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:48.865171Z","iopub.execute_input":"2025-06-13T09:50:48.865530Z","iopub.status.idle":"2025-06-13T09:50:55.019353Z","shell.execute_reply.started":"2025-06-13T09:50:48.865500Z","shell.execute_reply":"2025-06-13T09:50:55.017986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def yolo_result_to_boxes(res):\n    return res.boxes.xyxy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:55.020819Z","iopub.execute_input":"2025-06-13T09:50:55.021456Z","iopub.status.idle":"2025-06-13T09:50:55.027311Z","shell.execute_reply.started":"2025-06-13T09:50:55.021428Z","shell.execute_reply":"2025-06-13T09:50:55.026009Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## TrOCR","metadata":{"id":"QmmvZASGZUBs"}},{"cell_type":"code","source":"from transformers import GenerationConfig\n\n\ndef beam_search(model, processor):\n    model.config.decoder_start_token_id = processor.tokenizer.cls_token_id    \n    model.config.pad_token_id = processor.tokenizer.pad_token_id\n    model.config.vocab_size = model.config.decoder.vocab_size\n    \n    \n    # set beam search parameters\n    generation_config = GenerationConfig(        \n        max_length=64,\n        early_stopping=True,\n        no_repeat_ngram_size=3,\n        length_penalty=2.0,\n        num_beams=4\n    )\n    model.generation_config = generation_config\n    \n    model.generation_config.eos_token_id = processor.tokenizer.sep_token_id\n    model.generation_config.decoder_start_token_id = processor.tokenizer.cls_token_id\n    model.generation_config.pad_token_id = processor.tokenizer.pad_token_id","metadata":{"id":"oS4LlHYCtFUt","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:55.028352Z","iopub.execute_input":"2025-06-13T09:50:55.028733Z","iopub.status.idle":"2025-06-13T09:50:56.199162Z","shell.execute_reply.started":"2025-06-13T09:50:55.028708Z","shell.execute_reply":"2025-06-13T09:50:56.198095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import TrOCRProcessor, VisionEncoderDecoderModel\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel_name = \"/kaggle/input/trocr-base-ru-dialectic/pytorch/default/1\"\n\ntext_processor = TrOCRProcessor.from_pretrained(model_name)\ntext_recognition = VisionEncoderDecoderModel.from_pretrained(model_name)\n\nbeam_search(text_recognition, text_processor)\ntext_recognition.to(device)","metadata":{"id":"xuwvRO7Ph3t5","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:50:56.200790Z","iopub.execute_input":"2025-06-13T09:50:56.201380Z","iopub.status.idle":"2025-06-13T09:51:37.152267Z","shell.execute_reply.started":"2025-06-13T09:50:56.201345Z","shell.execute_reply":"2025-06-13T09:51:37.151136Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def recognize(image):\n    pixel_values = text_processor(images=image, return_tensors=\"pt\").pixel_values.to(device)\n\n    generated_ids = text_recognition.generate(pixel_values)\n    generated_text = text_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    return generated_text","metadata":{"id":"MadgJTh0wYAF","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T10:12:57.472514Z","iopub.execute_input":"2025-06-13T10:12:57.472919Z","iopub.status.idle":"2025-06-13T10:12:57.478674Z","shell.execute_reply.started":"2025-06-13T10:12:57.472876Z","shell.execute_reply":"2025-06-13T10:12:57.477570Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Text Detection","metadata":{"id":"VX6OngCLZxVX"}},{"cell_type":"markdown","source":"## Grouping detected regions by text lines","metadata":{"id":"W6FmeWZ_aCdQ"}},{"cell_type":"code","source":"def clamp(min_val, max_val, value):\n    return max(min(max_val, value), min_val)\n\ndef boxes_to_groups(boxes):\n    groups = []\n\n    for bi, box in enumerate(boxes):\n        added_to_group = False\n        \n        for gi, group in enumerate(groups):\n            for group_box in group:\n                y1 = clamp(box[1], box[3], group_box[1])\n                y2 = clamp(box[1], box[3], group_box[3])\n                y_overlap = (y2 - y1) / (box[3] - box[1])\n                \n                if y_overlap >= 0.6:\n                    group.append(box)\n                    added_to_group = True\n                    break\n            \n            if added_to_group:\n                break\n\n        if not added_to_group:\n            groups.append([box])\n\n    for group in groups:\n        group.sort(key=lambda box: box[0])\n    groups.sort(key=lambda group: group[0][1])\n\n    return groups","metadata":{"id":"eGd3mCWvavym","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:51:37.164185Z","iopub.execute_input":"2025-06-13T09:51:37.164552Z","iopub.status.idle":"2025-06-13T09:51:37.278918Z","shell.execute_reply.started":"2025-06-13T09:51:37.164524Z","shell.execute_reply":"2025-06-13T09:51:37.277825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\ndef combining_boxes(groups):\n\n    for gi, group in enumerate(groups):\n        i = 0\n\n        while i < len(group) - 1:\n            box_cur, box_next = group[i], group[i+1]\n\n            x1 = clamp(box_next[0], box_next[2], box_cur[0])\n            x2 = clamp(box_next[0], box_next[2], box_cur[2])\n            x_overlap = (x2 - x1) / (box_next[2] - box_next[0])\n\n            if x_overlap > 0:\n                new_box = torch.stack([\n                    torch.min(box_cur[0], box_next[0]), #xmin\n                    torch.min(box_cur[1], box_next[1]), #ymin\n                    torch.max(box_cur[2], box_next[2]), #xmax\n                    torch.max(box_cur[3], box_next[3]), #ymax\n                ])\n\n                group[i] = new_box\n\n                del group[i + 1]\n                i = max(i - 1, 0)\n            else:\n                i += 1\n\n    return groups","metadata":{"id":"vkH8dOv8SBTE","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T09:51:37.280106Z","iopub.execute_input":"2025-06-13T09:51:37.280447Z","iopub.status.idle":"2025-06-13T09:51:37.303495Z","shell.execute_reply.started":"2025-06-13T09:51:37.280420Z","shell.execute_reply":"2025-06-13T09:51:37.302562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\ndef show_groups(image, groups):\n    temp = image.copy()\n    groups = combining_boxes(groups)\n\n    for group in groups:\n        color = np.random.randint(256, size=3).tolist()\n\n        for box in group:\n            x1, y1, x2, y2 = map(int, box)\n            temp = cv2.rectangle(temp, (x1, y1), (x2, y2), color=color, thickness=3)\n\n    plt.figure(figsize=(15, 10))\n    plt.imshow(temp)\n    plt.axis('off')\n    plt.show()","metadata":{"id":"iljqYI84X87a","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T10:14:45.308157Z","iopub.execute_input":"2025-06-13T10:14:45.308641Z","iopub.status.idle":"2025-06-13T10:14:45.318452Z","shell.execute_reply.started":"2025-06-13T10:14:45.308579Z","shell.execute_reply":"2025-06-13T10:14:45.317018Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Text recognition","metadata":{"id":"QC-l-b7Tcrqd"}},{"cell_type":"code","source":"def recognize_text(image, groups):\n    result = ''\n\n    for group in groups:\n        for box in group:\n            x1, y1, x2, y2 = map(int, box)\n            crop = image[y1:y2, x1:x2]\n            word = recognize(crop)\n            result += word + ' '\n            \n        result = result[:-1]\n        result += '\\n'\n\n    result = result[:-1]\n    return result","metadata":{"id":"5EpxF0giZjH-","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T10:12:33.747504Z","iopub.execute_input":"2025-06-13T10:12:33.747870Z","iopub.status.idle":"2025-06-13T10:12:33.754640Z","shell.execute_reply.started":"2025-06-13T10:12:33.747841Z","shell.execute_reply":"2025-06-13T10:12:33.753462Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Full inference pipeline","metadata":{}},{"cell_type":"code","source":"for image in imgs:\n    yolo_result = text_detection(image, conf=0.3)[0]\n    yolo_boxes = yolo_result_to_boxes(yolo_result)\n    yolo_groups = boxes_to_groups(yolo_boxes)\n    combined_groups = combining_boxes(yolo_groups)\n\n    show_groups(image, combined_groups)\n    print(recognize_text(image, combined_groups))","metadata":{"id":"WZzvLhkzAE5C","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T10:13:04.358988Z","iopub.execute_input":"2025-06-13T10:13:04.359378Z","iopub.status.idle":"2025-06-13T10:14:04.326059Z","shell.execute_reply.started":"2025-06-13T10:13:04.359355Z","shell.execute_reply":"2025-06-13T10:14:04.324937Z"}},"outputs":[],"execution_count":null}]}